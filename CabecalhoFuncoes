type Network = [[[Float]]]

--Recebe uma lista com o numero de neuronios por layer e devolve uma lista de matrizes
--com os pesos das ligacoes
createNetwork :: [Int] -> Network

--Recebe o input da primeira layer [Float] e a rede (os pesos), calcula a soma
-- i*w e aplica a funcao de ativacao para cada neuronio. Devolve uma lista de listas,
--onde cada lista eh o output para cada layer

--Parte do Gustavo

type Network = [[[Float]]]

makeList :: Int -> [Float]
makeList 0 = []
makeList x = 1.0 : (makeList (x-1))

makeMatrix :: Int -> Int -> [[Float]]
makeMatrix 0 y = []
makeMatrix x y = ((makeList y) : (makeMatrix (x-1) y))

createNetwork :: [Int] -> Network
createNetwork [x]       = []
createNetwork (x:y:ys) = (makeMatrix y x) : (createNetwork (y:ys))

--Parte do Thiago

import Data.List

sigmoid :: Float -> Float -> Float
sigmoid x a = 1/(1 + exp(-a*x))

ativacao :: Float -> Float
ativacao a | a < 2 = 0
           | otherwise = 1

calculaAct :: [Float] -> [[Float]] -> (Float->Float) -> [Float]
calculaAct xs [] f      = []
calculaAct xs (y:ys) f  = [f $ sum $ zipWith (*) xs y] ++ calculaAct xs ys f

calcOutput :: [Float] -> Network -> (Float -> Float) -> [[Float]]
calcOutput xs [] f     = []
calcOutput xs (r:rs) f = [resultCamada] ++ calcOutput resultCamada rs f
    where
        resultCamada = calculaAct xs r f

-- calcOutput [1] (createNetwork [1,2,3]) (`sigmoid` 3.0)
-->[[0.95257413,0.95257413],[0.99671614,0.99671614,0.99671614]]
-- Ele cria uma rede com uma entrada, dois neurônios na parte intermediária e três neurônios na saída. O input é 1.0 e a saída
de cada camada é retornado pela função acima

-Fim da Parte do Thiago

--Funcao que recebe o output de uma layer e o resultado esperado e devolve
--o erro para cada neuronio
calcError :: [Float] -> [Float] -> [Float]

--Recebe a rede e a funcao de erro e realiza o backtracking:
--Calcula o erro do output
--Ajusta os pesos
--Calcula a saida esperada para a proxima layer
--Repete até chegar na primeira
backTracking :: Network -> (calcError) -> Network

--Recebe a rede e um conjunto de treinamento de tuplas (input, output)
--e realiza o backtracking para cada entrada
--Repete até que o criterio de parada (float) seja atingido
--Devolve os pesos finais
training :: Network -> [([Float],[Float])] -> Float -> Network
